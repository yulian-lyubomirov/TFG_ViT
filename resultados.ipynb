{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from functions.train_test import test\n",
    "from models.vit import ViT\n",
    "from models.CNN_ViT import CNN_ViT\n",
    "from models.CNN_ViT_dynamic import CNN_ViT_dynamic\n",
    "from models.CNN_ViT_early_exit import CNN_ViT_early_exit\n",
    "from functions.helpers import count_parameters\n",
    "from functions.plotter import plot_feature_maps, plot_loss_accuracy\n",
    "import functions as f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIFAR-100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = f.data_loader.get_data_loader(\n",
    "    80, 2, \"datasets/cifar-100/cifar-100-python\", download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN+ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ViT(\n",
    "    image_size=32,\n",
    "    patch_size=4,\n",
    "    num_classes=100,\n",
    "    dim=64,\n",
    "    depth=4,\n",
    "    heads=8,\n",
    "    mlp_dim=256,\n",
    "    dropout=0.1,\n",
    ").to(\"cpu\") #cpu for feature visualisation\n",
    "base_model_load_path = f\"save_model/cifar-100/vit_base/best_model.pt\"\n",
    "print(f\"Total parameters:{f.helpers.count_parameters(base_model)}\")\n",
    "f.data_loader.load_checkpoint(base_model,base_model_load_path)\n",
    "base_model_acc=test(base_model,test_loader,'cuda')\n",
    "base_model_loss_list,base_model_accuracy_list=f.data_loader.load_lists_from_file('save_model/cifar-100/vit_base/loss_and_accuracy')\n",
    "f.plotter.plot_loss_accuracy(base_model_loss_list,base_model_accuracy_list,'base_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN pre ViT feautre extraction + CNN patch embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_ViT_model = CNN_ViT(\n",
    "    image_size=32,\n",
    "    patch_size=4,\n",
    "    num_classes=100,\n",
    "    dim=64,\n",
    "    depth=2,\n",
    "    heads=4,\n",
    "    mlp_dim=256,\n",
    "    dropout=0.1,\n",
    ").to(\"cpu\")#cpu for feature visualisation\n",
    "CNN_ViT_model_load_path = \"save_model/cifar-100/CNN_ViT2/best_model.pt\"\n",
    "print(f\"Total parameters:{f.helpers.count_parameters(CNN_ViT_model)}\")\n",
    "f.data_loader.load_checkpoint(CNN_ViT_model,CNN_ViT_model_load_path)\n",
    "CNN_ViT_model_acc=test(CNN_ViT_model,test_loader,'cuda')\n",
    "CNN_ViT_model_loss_list,CNN_ViT_model_accuracy_list=f.data_loader.load_lists_from_file('save_model/cifar-100/CNN_ViT2/loss_and_accuracy')\n",
    "f.plotter.plot_loss_accuracy(CNN_ViT_model_loss_list,CNN_ViT_model_accuracy_list,'CNN_ViT_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.plotter.plot_accuracy_comparison(CNN_ViT_model_accuracy_list,base_model_accuracy_list,'CNN_ViT_model','ViT_base_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.data_loader.create_comparison_table([base_model,CNN_ViT_model],[base_model_acc,CNN_ViT_model_acc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.to('cpu')\n",
    "x,img=f.data_loader.get_random_image('bee')\n",
    "plot_feature_maps(base_model,x,img,device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_ViT_model.to('cpu')\n",
    "plot_feature_maps(CNN_ViT_model,x,img,device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN_ViT dynamic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_ViT_dynamic_model= CNN_ViT_dynamic(\n",
    "    image_size=32,\n",
    "    dim=64,\n",
    "    patch_size=4,\n",
    "    num_classes=100,\n",
    "    depth=4,\n",
    "    heads=4,\n",
    "    mlp_dim=256,\n",
    "    dropout=0.1,\n",
    "    inference=False\n",
    ").to(\"cuda\")\n",
    "CNN_ViT_dynamic_load_path ='save_model/cifar-100/CNN_ViT_dynamic/best_model.pt'\n",
    "\n",
    "#Explicar num parametros dependiendo de ruta tomada\n",
    "#Comprarar % de 'early_exits'\n",
    "#Ver tiempo de inferencia con 1 ejemplo para este y el modelo base\n",
    "\n",
    "print(f\"Total parameters:{f.helpers.count_parameters(CNN_ViT_dynamic_model)}\")\n",
    "f.data_loader.load_checkpoint(CNN_ViT_dynamic_model,CNN_ViT_dynamic_load_path)\n",
    "CNN_ViT_dynamic_model_acc=test(CNN_ViT_dynamic_model,test_loader,'cuda')\n",
    "CNN_ViT_dynamic_model_loss_list,CNN_ViT_dynamic_model_accuracy_list=f.data_loader.load_lists_from_file('save_model/cifar-100/CNN_ViT_dynamic/loss_and_accuracy')\n",
    "f.plotter.plot_loss_accuracy(CNN_ViT_dynamic_model_loss_list,CNN_ViT_dynamic_model_accuracy_list,'CNN_ViT_dynamic_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test dynamic model inference time with batch=1 and compare to base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_ViT_dynamic_model= CNN_ViT_dynamic(\n",
    "    image_size=32,\n",
    "    dim=64,\n",
    "    patch_size=4,\n",
    "    num_classes=100,\n",
    "    depth=4,\n",
    "    heads=8,\n",
    "    mlp_dim=256,\n",
    "    dropout=0.1,\n",
    "    inference=True\n",
    ").to(\"cuda\")\n",
    "f.data_loader.load_checkpoint(CNN_ViT_dynamic_model,CNN_ViT_dynamic_load_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowledge distillation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teacher logits based KD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_kd = ViT(\n",
    "    image_size=32,\n",
    "    patch_size=4,\n",
    "    num_classes=100,\n",
    "    dim=64,\n",
    "    depth=3,\n",
    "    heads=6,\n",
    "    mlp_dim=256,\n",
    "    dropout=0.1,\n",
    "    # feature_distill=True\n",
    ").to(\"cuda\")\n",
    "student_load_path = 'save_model/cifar-100/vit_featurekd/best_model.pt'\n",
    "print(f\"Total parameters:{f.helpers.count_parameters(student_kd)}\")\n",
    "f.data_loader.load_checkpoint(student_kd,student_load_path)\n",
    "student_kd_acc = test(student_kd,test_loader,'cuda')\n",
    "student_kd_loss_list,student_kd_accuracy_list = f.data_loader.load_lists_from_file('save_model/cifar-100/vit_featurekd/loss_and_accuracy')\n",
    "f.plotter.plot_loss_accuracy(student_kd_loss_list,student_kd_accuracy_list,'student_kd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_base_model = ViT(\n",
    "    image_size=32,\n",
    "    patch_size=4,\n",
    "    num_classes=100,\n",
    "    dim=64,\n",
    "    depth=3,\n",
    "    heads=6,\n",
    "    mlp_dim=256,\n",
    "    dropout=0.1,\n",
    ").to(\"cuda\")\n",
    "student_base_load_path = \"save_model/cifar-100/vit_16_student_base_cifar-100/best_model.pt\"\n",
    "print(f\"Total parameters:{f.helpers.count_parameters(student_base_model)}\")\n",
    "f.data_loader.load_checkpoint(student_base_model,student_base_load_path)\n",
    "student_base_model_acc = test(student_base_model,test_loader,'cuda')\n",
    "student_base_model_loss_list,student_base_model_accuracy_list = f.data_loader.load_lists_from_file('save_model/cifar-100/vit_16_student_base_cifar-100/loss_and_accuracy')\n",
    "f.plotter.plot_loss_accuracy(student_base_model_loss_list,student_base_model_accuracy_list,'student_base_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.plotter.plot_accuracy_comparison(student_kd_accuracy_list,student_base_model_accuracy_list,'student_kd','student_base_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.data_loader.create_comparison_table([student_kd,student_base_model],[student_kd_acc,student_base_model_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add inference time comparison and co2 eq "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN_ViT early exit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from functions.train_test import test\n",
    "from models.vit import ViT\n",
    "from models.CNN_ViT import CNN_ViT\n",
    "from models.CNN_ViT_dynamic import CNN_ViT_dynamic\n",
    "from models.CNN_ViT_early_exit import CNN_ViT_early_exit\n",
    "# from models.prueba_early_exit import prueba_early_exit\n",
    "from functions.helpers import count_parameters\n",
    "from functions.plotter import plot_feature_maps, plot_loss_accuracy\n",
    "import functions as f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = f.data_loader.get_data_loader(\n",
    "    80, 2, \"datasets/cifar-100/cifar-100-python\", download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_ViT_early_exit = CNN_ViT_early_exit(\n",
    "    image_size=32,\n",
    "    dim=64,\n",
    "    patch_size=4,\n",
    "    num_classes=100,\n",
    "    depth=6,\n",
    "    heads=6,\n",
    "    mlp_dim=256,\n",
    "    dropout=0.1,\n",
    "    early_exit=True\n",
    ").to(\"cuda\")\n",
    "CNN_ViT_early_exit_load_path='save_model/cifar-100/CNN_ViT_early_exit/best_model.pt'\n",
    "print(f\"Total parameters:{f.helpers.count_parameters(CNN_ViT_early_exit)}\")\n",
    "f.data_loader.load_checkpoint(CNN_ViT_early_exit,CNN_ViT_early_exit_load_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_ViT_early_exit_acc = test(CNN_ViT_early_exit,test_loader,'cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_1_example, test_loader_1_example = f.data_loader.get_data_loader(\n",
    "    1, 2, \"datasets/cifar-100/cifar-100-python\", download=True\n",
    ")\n",
    "CNN_ViT_early_exit_acc = test(CNN_ViT_early_exit,test_loader_1_example,'cuda')\n",
    "CNN_ViT_early_exit_loss_list,CNN_ViT_early_exit_model_accuracy_list = f.data_loader.load_lists_from_file('save_model/cifar-100/vit_early_exit_big/loss_and_accuracy')\n",
    "f.plotter.plot_loss_accuracy(CNN_ViT_early_exit_loss_list,CNN_ViT_early_exit_model_accuracy_list,'CNN_ViT_early_exit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
